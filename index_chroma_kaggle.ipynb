{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build Chroma DB on Kaggle and Download\n",
        "\n",
        "This notebook installs dependencies, loads your metadata and embeddings from the repo, builds a Chroma collection at `/kaggle/working/chroma_db`, and zips it for download.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "pip install --quiet chromadb langchain langchain_community langchain_core transformers torch pandas numpy tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Mount repo root - in Kaggle, this notebook should be placed at project root after uploading the repo as a dataset\n",
        "REPO_ROOT = Path(\"/kaggle/working\")  # Kaggle's working directory\n",
        "# If you upload the repo as input dataset, you can also set REPO_ROOT = Path(\"/kaggle/input/science-paper-qa-rag\")\n",
        "\n",
        "CHROMA_DIR = REPO_ROOT / \"chroma_db\"\n",
        "CHROMA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Chroma target dir:\", CHROMA_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add repo root and src/ to Python path to support both import styles\n",
        "import sys\n",
        "repo_root = str(REPO_ROOT)\n",
        "repo_src = str(REPO_ROOT / \"src\")\n",
        "for p in [repo_root, repo_src]:\n",
        "    if p not in sys.path:\n",
        "        sys.path.insert(0, p)\n",
        "print(\"Python path includes:\", repo_root, \"and\", repo_src)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Override persist dir to Kaggle working folder and point inputs to the Input Dataset\n",
        "try:\n",
        "    from src.pipeline.config import paths\n",
        "except ModuleNotFoundError:\n",
        "    from pipeline.config import paths\n",
        "from pathlib import Path\n",
        "\n",
        "# Inputs live under REPO_ROOT (often /kaggle/input/<dataset-name>)\n",
        "paths.abs_metadata_path = str(REPO_ROOT / \"data\" / \"abs_metadata.json\")\n",
        "paths.finetuned_questions_embeddings_csv = str(REPO_ROOT / \"src\" / \"citation_net\" / \"finetune_embedding_model\" / \"combined_doi_questions_embeddings.csv\")\n",
        "paths.graphsage_embeddings_csv = str(REPO_ROOT / \"src\" / \"citation_net\" / \"graphSAGE\" / \"graphsage_embeddings.csv\")\n",
        "\n",
        "# Output (persisted Chroma) in working dir\n",
        "paths.chroma_persist_dir = str(CHROMA_DIR)\n",
        "\n",
        "print(\"Chroma persist dir set to:\", paths.chroma_persist_dir)\n",
        "print(\"Emb CSV:\", paths.finetuned_questions_embeddings_csv, Path(paths.finetuned_questions_embeddings_csv).exists())\n",
        "print(\"Metadata:\", paths.abs_metadata_path, Path(paths.abs_metadata_path).exists())\n",
        "print(\"GraphSAGE:\", paths.graphsage_embeddings_csv, Path(paths.graphsage_embeddings_csv).exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sanity check input files exist (mounted with the repo / uploaded as dataset)\n",
        "from pathlib import Path\n",
        "\n",
        "required_files = [\n",
        "    REPO_ROOT / \"data\" / \"abs_metadata.json\",\n",
        "    REPO_ROOT / \"src\" / \"citation_net\" / \"finetune_embedding_model\" / \"combined_doi_questions_embeddings.csv\",  # only for ID list filtering\n",
        "]\n",
        "for p in required_files:\n",
        "    print(p, \"exists:\", p.exists())\n",
        "\n",
        "assert all(p.exists() for p in required_files), \"Missing required input files in Kaggle environment. Upload the repo or set REPO_ROOT accordingly.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the Chroma collection\n",
        "try:\n",
        "    from src.pipeline.index_chroma import build_chroma_collection\n",
        "except ModuleNotFoundError:\n",
        "    from pipeline.index_chroma import build_chroma_collection\n",
        "\n",
        "build_chroma_collection()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zip the Chroma DB for download\n",
        "import shutil\n",
        "zip_path = REPO_ROOT / \"chroma_db.zip\"\n",
        "if zip_path.exists():\n",
        "    zip_path.unlink()\n",
        "shutil.make_archive(str(zip_path.with_suffix('')), 'zip', CHROMA_DIR)\n",
        "zip_path.exists(), zip_path, CHROMA_DIR\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hướng dẫn tải về trên Kaggle\n",
        "- Sau khi chạy xong, file zip nằm ở `/kaggle/working/chroma_db.zip`.\n",
        "- Vào tab Output/Files của notebook Kaggle để download.\n",
        "\n",
        "## Tùy chỉnh\n",
        "- Muốn thay vị trí DB: đổi `CHROMA_DIR` ở ô đầu.\n",
        "- Nếu bạn upload repo dưới dạng Input Dataset ở Kaggle, hãy đặt `REPO_ROOT = Path(\"/kaggle/input/<dataset-name>\")` và copy code/inputs vào `/kaggle/working` trước khi build nếu cần.\n",
        "- Nếu cần chỉ số khác (cosine/l2), sửa trong `src/pipeline/index_chroma.py` khi tạo collection.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
